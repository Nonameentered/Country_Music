genres <- gsub(".*name: ", "", genres)
# Removes all instances of , (including the space after the ,) and everything up to a line termination or end-of-string for each vector element
genres <- gsub(", .*", "", genres)
sort(table(genres), decreasing = T)
# Sorts the table of genres by # of movies in decreasing order and creates a subset between the 6th and 19th (last) element. Then takes the vector of genre names from that subset and puts that vector into uncommon
(uncommon <- names(sort(table(genres), decreasing = T)[6:19]))
# For each element in the genres vector, if the element matches one of the genre names in the uncommon vector, changes that element to Other
genres[genres %in% uncommon] <- "Other"
# Creates a table of genres sorted in decreasing order of movie-in-genre count, with the previous 6th-19th categories all grouped into the Other count
sort(table(genres), decreasing = T)
# Creates a new column in the movie dataframe called CleanGenre, and assigns it to be a copy of genres after our above manipulations
movie$CleanGenre <- genres
library(car)
qqPlot(movie$revenue, pch = 19)
qqPlot(log(movie$revenue), pch = 19)
# tempBudRev <- na.omit(movie[, c("budget", "revenue")]) An alternative way of filtering for complete data
tempBudRev <- movie[!is.na(movie$budget) & !is.na(movie$revenue), c("budget", "revenue")]
# Bootstrap
N <- nrow(tempBudRev)
n_samp <- 10000
corResults <- rep(NA, n_samp)
for(i in 1:n_samp){
#get vector of rows in our fake sample
s <- sample(1:N, N , replace = T)
fakeData <-  tempBudRev[s, ]
#Get bootstrapped correlation and regression slope
corResults[i] <- cor(log(fakeData[, 1]), log(fakeData[, 2]))
}
ci_r <- quantile(corResults, c(.025, .975))
# Plot
plot(log(tempBudRev$budget), log(tempBudRev$revenue), xlab = "Budget - Transformed by log(x/$1 mil)", ylab = "Revenue - Transformed by log(x/$1 mil)", pch = 19, cex.lab=0.7)
mtext(line = 1, cex = 0.9, "Revenue vs. Budget - Transformed by log(x/$1 mil)")
mtext(line = 0, cex = 0.8, paste0("Correlation = ", round(cor(log(tempBudRev$budget), log(tempBudRev$revenue)), 2), ", 95% Bootstrap CI = (", round(ci_r[1], 2), ",", round(ci_r[2], 2), ")"))
movie$PctReturn <- movie$revenue / movie$budget * 100
boxplot(movie$PctReturn ~ movie$CleanGenre, col = "yellow", main = "Percent Return for Movie by Genre", ylab = "Percent Return", xlab = "Cleaned Movie Genres", cex.axis = .6)
abline(h = 100, lwd = 3, col = "blue", lty = 2)
movie2 <- movie[movie$CleanGenre == "Animation" | movie$CleanGenre == "Drama",]
movie2 <- movie2[!is.na(movie2$PctReturn), ]
dim(movie2)
# (parm_ci <- t.test(movie2[movie2$CleanGenre == "Animation", ]$PctReturn ~ movie2[movie2$CleanGenre == "Drama", ]$PctReturn))
(parm_ci <- t.test(movie2$PctReturn ~ movie2$CleanGenre))
#Set number of bootstrap samples to take
N <- 10000
#Make empty vector for sample mean differences
diffFilms <- rep(NA, N)
for (i in 1:N) {
sAnimation <- sample(movie2$PctReturn[movie2$CleanGenre == "Animation"],
sum(movie2$CleanGenre == "Animation"), replace = TRUE)
sDrama <- sample(movie2$PctReturn[movie2$CleanGenre == "Drama"],
sum(movie2$CleanGenre == "Drama"), replace = TRUE)
diffFilms[i] <- mean(sAnimation) - mean(sDrama)
}
ci <- quantile(diffFilms, c(0.025, 0.975))
hist(diffFilms, col = "blue", main = "Bootstrapped Sample Means Diff in Film Percent Return", xlab = "Dollars", breaks = 50, cex.main=0.9)
#Add lines to histogram for CI's
abline(v = ci, lwd = 3, col = "red")
abline(v = parm_ci$conf.int, lwd = 3, col = "green", lty = 2)
legend("topright", c("Parametric CI","Boot CI"), lwd = 3, col = c("green","red"), lty = c(2,1))
#
movie4 <- na.omit(movie[, c("title", "budget", "revenue", "PctReturn")])
Award <- rep(NA, 6) # EDIT - make this a 6 element vector filled with NA
results <- NULL
for (i in 2:4){
Award[2*(i-1)-1] <- paste("Max", names(movie4)[i]) # EDIT - paste the word "Max" with the ith element of the names of movie4
Award[2*(i-1)] <- paste("Min", names(movie4)[i]) # EDIT - paste the word "Min" with the ith element of the names of movie4
max <- movie4[which.max(movie4[,i]),] # EDIT - return the row information of movie4 such that the ith column of movie4 is equal to the max of the ith column of movie4
min <- movie4[which.min(movie4[,i]),] # EDIT - return the row information of movie4 such that the ith column of movie4 is equal to the min of the ith column of movie4
results <- rbind(results, max, min)
}
cbind(Award, results)
myTitle <- head(movie$title, 20)
myTitle <- tolower(myTitle)
myTitle <- gsub("john", "jimmy", myTitle)
myTitle <- gsub("^a", "A", myTitle)
myTitle <- gsub("man|men", "shrubbery", myTitle)
myTitle
boxplot(movie$budget, width = 2, col = "orange", horizontal = TRUE, main = "Movie Budgets", xlab = "Dollars", cex.lab=0.9)
boxplot(movie$budget, width = 2, col = "orange", horizontal = TRUE, main = "Movie Budgets", xlab = "Dollars", cex=0.9)
boxplot(movie$budget, width = 2, col = "orange", horizontal = TRUE, main = "Movie Budgets", xlab = "Dollars", cex=0.9)
boxplot(movie$budget, width = 2, col = "orange", horizontal = TRUE, main = "Movie Budgets", xlab = "Dollars", cex.axis=0.9)
boxplot(movie$budget, width = 2, col = "orange", horizontal = TRUE, main = "Movie Budgets", xlab = "Dollars", cex.axis=0.4)
knitr::opts_chunk$set(echo = TRUE)
set.seed(1)
simdata <- rnorm(10*15) # need 10 * 15 values simulated
simdata <- matrix(simdata, nrow=10, ncol=15) # now convert this vector into a matrix
colnames(simdata) <- c("y", paste0("x", 1:14)) # add column names
simdata <- as.data.frame(simdata) # convert the matrix into a data frame
colnames(simdata)
knitr::opts_chunk$set(echo = TRUE)
#Get data
crosby <-  read.csv("http://www.reuningscherer.net/S&DS230/data/CrosbyMin.csv")
#Remove missing values
crosby <- na.omit(crosby)
#Make some new variables to avoid lots of typing
Mintemp <- crosby$Annual.Min.Temp
Year <- crosby$Year
#Fit a linear model
lm1 <- lm(Mintemp ~ Year)
summary(lm1)
#Fit a quadratic model - create Year squared variable
YearSq <- Year^2
lm2 <- lm(Mintemp ~ Year + YearSq)
summary(lm2)
#Quick plot with linear regression model
plot(crosby, col = 'red', pch = 19)
abline(lm1$coef, col = "blue", lwd = 3)
mtext("Avg. Min Monthly Temp in Crosby, ND", line = 1, cex = 1.2)
mtext(paste("TEMP =", round(lm1$coef[1], 3)," + ", round(lm1$coef[2], 3), "*YEAR"), line = 0)
mod1 <- lm(simdata$y ~ simdata$x1)
mod1
summary(mod1)
summary(mod1)$r.squared
summary(mod1)
simtemp <- simdata[,1:8]
m7 <- lm(y ~ ., data=simtemp)
colnames(simdata)
length(colnames(simdata))
rsqvals = rep(NA, length(colnames(simdata)) - 1)
rsqvals
rsqvals = rep(NA, 14)
for(i in 1:14) {
rsqvals[i] <- lm(y ~ ., data=simdata[,1:i])
}
simdata
simdata[,1:i]
simdata[,1:8]
simdata[,1:1]
simdata
rsqvals = rep(NA, 14)
for(i in 2:15) {
rsqvals[i] <- lm(y ~ ., data=simdata[,1:i])
}
rsqvals = rep(NA, 14)
for(i in 1:14) {
rsqvals[i] <- lm(y ~ ., data=simdata[,1:(i + 1)])
}
simdata[,1:(i + 1)]
lm(y ~ ., data=simdata[,1:(i + 1)])
lm(y ~ ., data=simdata[,1:(i + 1)])$r.squared
rsqvals = rep(NA, 14)
for(i in 1:14) {
rsqvals[i] <- summary(lm(y ~ ., data=simdata[,1:(i + 1)]))$r.squared
}
rsqvals
which(rsqvals = 1)
which(rsqvals == 1, arr.ind = TRUE)
which(rsqvals == 1, arr.ind = TRUE)[0]
which(rsqvals == 1, arr.ind = TRUE)[1]
plot(rsqvals)
plot(rsqvals, xlab = "Predictors")
plot(rsqvals, xlab = "Predictors", ylab = "R-squared")
plot(rsqvals, xlab = "Predictors", ylab = "R-squared", main = "Rsquared vs Predictors")
colnames(crime)
crime <- read.csv("http://reuningscherer.net/s&ds230/data/ohiocrime.csv")
dim(crime)
colnames(crime)
crime[10:23]
#round cor1 to 2 decimal places and display the result.
round(cor1, 2)
#Load the corrplot package
library(corrplot)
cor1 <- cor(crime[10:23], use = "pairwise.complete.obs") #calculate pairwise correlations for columns 10-23 of crime.  You'll need the   use = "pairwise.complete.obs" option.
#round cor1 to 2 decimal places and display the result.
round(cor1, 2)
#WRITE A DESCRIPTION HERE OF THE PURPOSE OF THE FOLLOWING LINE.
maxloc <- which(cor1 == max(cor1[cor1<1]), arr.ind = TRUE)
View(lm2)
cor1[cor1<1]
max(cor1[cor1<1])
cor1
which(cor1 == max(cor1[cor1<1]), arr.ind = TRUE)
cor1 == max(cor1[cor1<1])
which(cor1 == max(cor1[cor1<1]), arr.ind = TRUE)
maxloc[1,]
maxloc[1,]
[maxloc[1,]]
3])[maxloc[1,]]
# Gets the indices for the pair of questions most correlated to each other, but not 1 (as all questions are most correlated to themselves)
maxloc <- which(cor1 == max(cor1[cor1<1]), arr.ind = TRUE)
#WRITE A DESCRIPTION HERE OF THE PURPOSE OF THE FOLLOWING LINE.
names(crime[10:23])[maxloc[1,]]
maxloc[1,]
[maxloc[1,]]
#WRITE A DESCRIPTION HERE OF THE PURPOSE OF THE FOLLOWING LINE.
names(crime[10:23])[maxloc[1,]]
crime[10:23]
maxloc[1,]
maxloc
# Get's the name of the
names(crime[10:23])[maxloc[1,]]
# Gets the indices for the pair of questions most correlated to each other, but not 1 (as all questions are most correlated to themselves)
maxloc <- which(cor1 == max(cor1[cor1<1]), arr.ind = TRUE)
# Get's the name of the
names(crime[10:23])[maxloc[1,]]
maxloc
maxloc[1,]
maxloc
crime[10:23]
cor.test(crime[10:23])
cor.mtest(crime[10:23])
cor.mtest(crime[10:23], conf.level = 0.95)
knitr::opts_chunk$set(echo = TRUE)
#Some handy libraries
library(car)
#Make object called WB4 which has complete data for variables we care about
WB4 <- na.omit(WB3[, c("log.TD", "Guns_per_100", "Fertility16", "logGNI", "LifeExp")])
knitr::opts_chunk$set(echo = TRUE)
#Some handy libraries
library(car)
guns <- read.csv("http://www.reuningscherer.net/s&ds230/data/GunDeath.csv", as.is = TRUE)
head(guns)
#Fix Country Names
guns$Country <- gsub(" [!].*", "", guns$Country)
head(guns)
#Fix Year
guns$Year <-as.integer(gsub(c("[(]incomplete[)]|[-]"),"",guns$Year))
#Fix type of death columns
for (i in 4:7){
guns[, i] <- as.numeric(gsub("unavailable|[(].*[)]","", guns[, i]))
}
#What is up with Guns_per_100?
guns$Guns_per_100
#Replace ?
guns$Guns_per_100 <- as.numeric(gsub("[?]", "", guns$Guns_per_100))
#Change deaths per gun per year to deaths per 10,000 guns per year
guns$Per_Gun_Per_Year <- guns$Per_Gun_Per_Year*10000
#Check final results
head(guns)
#How many countries do we have?
dim(guns)
#get data
WB <- read.csv("http://reuningscherer.net/multivariate/data/WB.2016.WithTrans.csv", header = T, as.is = T)
names(WB)
#Which countries match?  Only 67 of 74 countries matched
(both <- intersect(guns$Country, WB$Country))
#Which countries didn't find matches in WB?
guns$Country[!guns$Country %in% both]
#Manually get corresponding values in the WB dataset if the exist - Taiwan is not in [World Bank Data!](https://datahelpdesk.worldbank.org/knowledgebase/articles/114933-where-are-your-data-on-taiwan)
WB$Country
#Make Replacements in guns data based on WB designations - notice that I skip over Taiwan (since it's not in WB data)
guns$Country[!guns$Country %in% both][c(1:5, 7)] <- WB$Country[c(86, 107, 118, 173, 104, 211)]
#Check new matches - now all but Taiwan match
(both <- intersect(guns$Country, WB$Country))
#Use merge to combine the datasets.  The all = TRUE option means that all rows for both datasets will be retained.
WB2 <- merge(WB, guns, by = "Country", all = TRUE)
head(WB2)
#Dimensions of combined data should be one more than original data (i.e. add row for Taiwan)
dim(WB)
dim(WB2)
names(WB2)
boxplot(WB2$Total, col = "red", main = "Total Gun Deaths per 100,000", horizontal = T)
hist(WB2$Total, col = "red", main = "Total Gun Deaths per 100,000")
qqPlot(WB2$Total, main = "QQ Plot Gun Deaths per 100,000", pch = 19)
#Make variable on log scale
WB2$logTotal <- log(WB2$Total)
boxplot(WB2$logTotal, col = "red", main = "Log Total Gun Deaths per 100,000", horizontal = T)
#add line for log(rate) for USA
abline(v = WB2$logTotal[WB2$Country=="United States"], col = "blue", lwd = 3, lty = 2)
hist(WB2$logTotal, col = "red", main = "Log Total Gun Deaths per 100,000")
qqPlot(WB2$logTotal, main = "QQ Plot Log Gun Deaths per 100,000", pch = 19)
plot(WB2$logTotal, rep(1, length(WB2$logTotal)), type = "n", ylab = "", xlab = "log Total Gun Deaths", yaxt = "n")
text(WB2$logTotal, rep(1, length(WB2$logTotal)), WB2$Country, cex = .7, srt = 90)
boxplot(WB2$Guns_per_100, col = "red", main = "Total Guns per 100", horizontal = T)
#Which point is the outlier?
library(TeachingDemos)
library(plyr)
source("https://raw.githubusercontent.com/talgalili/R-code-snippets/master/boxplot.with.outlier.label.r") # Load the function
boxplot.with.outlier.label(WB2$Guns_per_100, WB2$Country, col = "red", main = "Total Guns per 100")
#Normal Quantile plot
qqPlot(WB2$Guns_per_100, main = "QQ Plot Guns per 100 people", pch = 19)
#not really exponentially distributed.   Maybe try square-root since it's sort of Poisson distribution
qqPlot(sqrt(WB2$Guns_per_100), main = "QQ Plot Sqrt(Guns per 100)", pch=19)
qqPlot(log(WB2$Guns_per_100), main = "QQ Plot log(Guns per 100)", pch=19)
#Use outlier function
boxplot.with.outlier.label(WB2$Per_Gun_Per_Year, WB2$Country, col = "red", main = "Deaths per 100")
#What about on log scale?
boxplot.with.outlier.label(log(WB2$Per_Gun_Per_Year), WB2$Country, col = "red", main = "Log Total Guns per 100")
#add line for log(rate) for USA
abline(h = log(WB2[WB2$Country=="United States", 32]), col = "blue", lwd = 3, lty = 2)
#here is plot on raw scale
plot(Total ~ Guns_per_100, data = WB2, col = "red", pch = 19, main = "Total Gun Death Rate vs Guns per 100")
#Relationship will probably be clearer on the log scale in both directions, or maybe sqrt for Guns per 100
plot(log(Total) ~ sqrt(Guns_per_100), data = WB2, col = "red", pch = 19, main = "Sqrt Scale Total Gun Death Rate vs Guns per 100")
#To make things cleaner, create a new dataset with just variables we care about.  Also, put country names on rows.
#In addition, make the first column log of Total deaths
names(WB2)
WB3 <- cbind(log(WB2$Total), WB2[, c("Guns_per_100","Fertility16","logGNI","LifeExp","Rural","logCO2","InfMort","Cell","logExports","logImports","logEnergyUse","newForest")])
head(WB3)
rownames(WB3) <- WB2[, 1]
colnames(WB3)[1] <- "log.TD"
names(WB3)
#Make object called WB4 which has complete data for variables we care about
WB4 <- na.omit(WB3[, c("log.TD", "Guns_per_100", "Fertility16", "logGNI", "LifeExp")])
#Get library for correlation plot
library(corrplot)
#Make correlation plot for retained variables
sigcorr <- cor.mtest(WB4, conf.level = .95)
corrplot.mixed(cor(WB4), lower.col="black", upper = "ellipse", tl.col = "black", number.cex=.7,
tl.pos = "lt", tl.cex=.7, p.mat = sigcorr$p, sig.level = .05)
#note the options above are to make plots work properly in the corrplot package.
#Load the corrplot package
library(corrplot)
cor1 <- cor(crime[10:23], use = "pairwise.complete.obs") #calculate pairwise correlations for columns 10-23 of crime.  You'll need the   use = "pairwise.complete.obs" option.
#round cor1 to 2 decimal places and display the result.
round(cor1, 2)
# Gets the indices for the pair of questions most correlated to each other, but not 1 (as all questions are most correlated to themselves)
maxloc <- which(cor1 == max(cor1[cor1<1]), arr.ind = TRUE)
# Get's the names of which questions are most correlated to one another
names(crime[10:23])[maxloc[1,]]
#Create an object called sigcorr that has the results of cor.mtest for columns 10-23 of the crime data.  Use 95% CI.
sigcorr <- cor.mtest(crime[10:23], conf.level = 0.95)
#Use corrplot.mixed to display confidence ellipses, pairwise correlation values, and put on 'X' over non-significant values.
corrplot.mixed(cor1, lower.col = "black", upper = "ellipse", tl.col = "black", number.cex=.7,
tl.pos = "lt", tl.cex=.7, p.mat = sigcorr$p, sig.level = .05)
, upper = "ellipse", tl.col = "black", number.cex=.5,
#Use corrplot.mixed to display confidence ellipses, pairwise correlation values, and put on 'X' over non-significant values.
corrplot.mixed(cor1, lower.col = "black", upper = "ellipse", tl.col = "black", number.cex=.5,
tl.pos = "lt", tl.cex=.5, p.mat = sigcorr$p, sig.level = .05)
#Use corrplot.mixed to display confidence ellipses, pairwise correlation values, and put on 'X' over non-significant values.
corrplot.mixed(cor1, lower.col = "black", upper = "ellipse", tl.col = "black", number.cex=.6,
tl.pos = "lt", tl.cex=.6, p.mat = sigcorr$p, sig.level = .05)
#note the options above are to make plots work properly in the corrplot package.
#Load the corrplot package
library(corrplot)
cor1 <- cor(crime[10:23], use = "pairwise.complete.obs") #calculate pairwise correlations for columns 10-23 of crime.  You'll need the   use = "pairwise.complete.obs" option.
#round cor1 to 2 decimal places and display the result.
round(cor1, 2)
# Gets the indices for the pair of questions most correlated to each other, but not 1 (as all questions are most correlated to themselves)
maxloc <- which(cor1 == max(cor1[cor1<1]), arr.ind = TRUE)
# Get's the names of which questions are most correlated to one another
names(crime[10:23])[maxloc[1,]]
#Create an object called sigcorr that has the results of cor.mtest for columns 10-23 of the crime data.  Use 95% CI.
sigcorr <- cor.mtest(crime[10:23], conf.level = 0.95)
#Use corrplot.mixed to display confidence ellipses, pairwise correlation values, and put on 'X' over non-significant values.
corrplot.mixed(cor1, lower.col = "black", upper = "ellipse", tl.col = "black", number.cex=.6,
tl.pos = "lt", tl.cex=.6, p.mat = sigcorr$p, sig.level = .05)
knitr::opts_chunk$set(echo = TRUE)
install.packages("RSQLite")
setwd("~/Code/Country")
conn <- dbConnect(RSQLite::SQLite(), "files/country_song_project.db")
knitr::opts_chunk$set(echo = TRUE)
library(stm)
library(tidyverse)
# library(DBI)
library(RSQLite)
conn <- dbConnect(RSQLite::SQLite(), "files/country_song_project.db")
dbSongs <- dbGetQuery(mydb, 'SELECT * FROM songs LIMIT 5')
dbSongs <- dbGetQuery(conn, 'SELECT * FROM songs LIMIT 5')
View(dbSongs)
knitr::opts_chunk$set(echo = TRUE)
df <- data.table::fread(file = "booksummaries.txt")
View(df)
conn <- dbConnect(RSQLite::SQLite(), "files/country_song_project.db")
dbSongs <- dbGetQuery(conn, 'SELECT * FROM songs')
dbDisconnect(conn)
conn <- dbConnect(RSQLite::SQLite(), "files/country_song_project.db")
dbSongs <- dbGetQuery(conn, 'SELECT * FROM songs')
dbLyrics <- dbGetQuery(conn, 'SELECT * FROM lyrics')
dbWords <- dbGetQuery(conn, 'SELECT * FROM Words')
dbDisconnect(conn)
conn <- dbConnect(RSQLite::SQLite(), "files/country_song_project.db")
dbSongs <- dbGetQuery(conn, 'SELECT * FROM songs')
dbLyrics <- dbGetQuery(conn, 'SELECT * FROM lyrics')
dbWords <- dbGetQuery(conn, 'SELECT * FROM Words')
dbDisconnect(conn)
library(stm)
library(tidyverse)
df <- data.table::fread(file = "booksummaries.txt")
# Give the columns names for easier reference. The names are taken
# from the dataset's webpage
names(df) <- c("wikipedia_id", "freebase_id", "book_title", "book_author",
"publication_date", "genres", "text")
# Create a binary variable indicating whether book is a work of fiction
df <- df %>%
mutate(fict = tolower(genres), # First creates fict as a lowercase version of genres
# if "fiction" appears in "genres", assign a 1; otherwise, 0
fict = ifelse(grepl("fiction", fict), 1, 0))
# Turn publication date into numeric variable of year
df <- df %>%
mutate(year = str_split_fixed(publication_date, "-", n = 3)[,1],
year = as.numeric(year))
# Create unique id
df <- df %>%
mutate(id = seq(1, dim(df)[1], 1),
id = paste0("id", id))
# Take another look to make sure the column names are updated
glimpse(df)
# Dataframe containing the text
docs_df <- df %>%
dplyr::select(id, text) %>%
# the objects need to be class "data frame"
as.data.frame()
df <- data.table::fread(file = "booksummaries.txt")
# Give the columns names for easier reference. The names are taken
# from the dataset's webpage
names(df) <- c("wikipedia_id", "freebase_id", "book_title", "book_author",
"publication_date", "genres", "text")
# Create a binary variable indicating whether book is a work of fiction
df <- df %>%
mutate(fict = tolower(genres), # First creates fict as a lowercase version of genres
# if "fiction" appears in "genres", assign a 1; otherwise, 0
fict = ifelse(grepl("fiction", fict), 1, 0))
# Turn publication date into numeric variable of year
df <- df %>%
mutate(year = str_split_fixed(publication_date, "-", n = 3)[,1],
year = as.numeric(year))
# Create unique id
df <- df %>%
mutate(id = seq(1, dim(df)[1], 1),
id = paste0("id", id))
# Take another look to make sure the column names are updated
glimpse(df)
# Dataframe containing the text
docs_df <- df %>%
dplyr::select(id, text) %>%
# the objects need to be class "data frame"
as.data.frame()
# A sample of the data, essentially
df_sample <- df %>%
# first, remove observation with missing values of the meta variables
filter(!is.na(year))
df_sample <- df %>%
filter(!is.na(fict))
# Unlike the example, do not take only a sample
df_sample <- df_sample[1:6000,]
# Dataframe of a sample of the documents
docs_sample <- df_sample %>%
dplyr::select(id, text) %>%
# trim whitespace from the text to make it cleaner
mutate(text = trimws(text)) %>%
# the objects need to be class "data frame"
as.data.frame()
# Dataframe containing (sample) documents' metadata of interest
meta_sample <- df_sample %>%
dplyr::select(id, year, fict) %>%
# the objects need to be class "data frame"
as.data.frame()
View(docs_sample)
vignette('stmVignette')
# A sample of the data, essentially
df_sample <- df %>%
# first, remove observation with missing values of the meta variables
filter(!is.na(year))
df_sample <- df %>%
filter(!is.na(fict))
# Unlike the example, do not take only a sample
df_sample <- df_sample[1:6000,]
# Dataframe of a sample of the documents
docs_sample <- df_sample %>%
dplyr::select(id, text) %>%
# trim whitespace from the text to make it cleaner
mutate(text = trimws(text)) %>%
# the objects need to be class "data frame"
as.data.frame()
# Dataframe containing (sample) documents' metadata of interest
meta_sample <- df_sample %>%
dplyr::select(id, year, fict) %>%
# the objects need to be class "data frame"
as.data.frame()
View(df_sample)
conn <- dbConnect(RSQLite::SQLite(), "files/country_song_project.db")
dbSongs <- dbGetQuery(conn, 'SELECT * FROM songs')
dbLyrics <- dbGetQuery(conn, 'SELECT * FROM lyrics')
dbWords <- dbGetQuery(conn, 'SELECT * FROM Words')
dbDisconnect(conn)
View(dbSongs)
docs_sample$text <-
# keep only alphabet letters and numbers ("al" and "num")
str_replace_all(docs_sample$text, "[^[:alnum:]]", " ") %>%
# make multiple spaces into one space
str_replace_all(.,"[ ]+", " ")
View(meta_sample)
View(docs_sample)
View(dbLyrics)
processed_docs_1 <- textProcessor(documents = docs_sample$text,
metadata = meta_sample,
lowercase = TRUE,
removestopwords = TRUE,
removenumbers = TRUE,
removepunctuation = TRUE,
ucp = TRUE,
stem = TRUE,
striphtml = TRUE,
wordLengths = c(3, Inf),
language = "en")
View(docs_sample)
View(docs_sample)
View(dbLyrics)
View(docs_sample)
View(dbWords)
alcoholWords = []
alcoholWords <- []
alcoholWords <- c()
relevantWords <- c("love")
perspective <- c("i", "we", "you")
america <- c("america", "american")
conn <- dbConnect(RSQLite::SQLite(), "files/country_song_project.db")
dbSongs <- dbGetQuery(conn, 'SELECT * FROM songs')
dbLyrics <- dbGetQuery(conn, 'SELECT * FROM lyrics')
dbWords <- dbGetQuery(conn, 'SELECT * FROM Words')
dbDisconnect(conn)
View(dbWords)
alcoholWords <- c("alcohol", "beer", "whiskey", "rum", "tequila")
relevantWords <- c("love")
perspective <- c("i", "we", "you")
america <- c("america", "american", "countri") #maybe also counti for county?
feelings <- c("dream", "hope", "sad", "tear", "")
romance <- c("girl", "beer")
songsAboutCountry <- c("country", "dirt", "road", "truck")
cursing <- c("fuck", "sin", "shit", "bullshit", "hell", "sinner", "goddamn", "Jesus Christ", "ass")
religious <- c("jesus", "christ", "god")
conn <- dbConnect(RSQLite::SQLite(), "files/country_song_project.db")
